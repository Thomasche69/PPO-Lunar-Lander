{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaomeiwang/Desktop/DeepRL/my_lunar_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from ale_py import ALEInterface\n",
    "import optuna\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters for PPO\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 256, 4096, step=256)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512])\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.95, 0.999, step=0.005)\n",
    "    gae_lambda = trial.suggest_float(\"gae_lambda\", 0.85, 0.99, step=0.01)\n",
    "    clip_range = trial.suggest_float(\"clip_range\", 0.1, 0.3, step=0.05)\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 1e-4, 0.1, log=True)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 3, 10)\n",
    "    \n",
    "    # Create the environment\n",
    "    env = DummyVecEnv([lambda: gym.make(\"LunarLander-v3\") for _ in range(4)])\n",
    "    \n",
    "    # Define the PPO model with the suggested hyperparameters\n",
    "    model = PPO(\n",
    "        policy=\"MlpPolicy\",\n",
    "        env=env,\n",
    "        learning_rate=learning_rate,\n",
    "        n_steps=n_steps,\n",
    "        batch_size=batch_size,\n",
    "        gamma=gamma,\n",
    "        gae_lambda=gae_lambda,\n",
    "        clip_range=clip_range,\n",
    "        ent_coef=ent_coef,\n",
    "        verbose=0,  # Suppress training logs for faster optimization\n",
    "        n_epochs=n_epochs\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Train the model\n",
    "        model.learn(total_timesteps=50000)  # Increased training timesteps\n",
    "\n",
    "        # Evaluate the model\n",
    "        mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "\n",
    "        # Report intermediate results for Optuna pruning\n",
    "        trial.report(mean_reward, step=0)\n",
    "\n",
    "        # Check for pruning\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    finally:\n",
    "        # Ensure the environment is properly closed\n",
    "        env.close()\n",
    "    \n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-14 10:54:30,709] A new study created in memory with name: no-name-3fb966be-5876-4fc9-88fd-7cfff9b832b5\n",
      "/Users/xiaomeiwang/Desktop/DeepRL/my_lunar_env/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "[I 2024-12-14 10:55:06,575] Trial 0 finished with value: -110.04965961286435 and parameters: {'learning_rate': 0.005181324715204164, 'n_steps': 2048, 'batch_size': 32, 'gamma': 0.98, 'gae_lambda': 0.9099999999999999, 'clip_range': 0.25, 'ent_coef': 0.03580541456076328, 'n_epochs': 5}. Best is trial 0 with value: -110.04965961286435.\n",
      "[I 2024-12-14 10:55:39,886] Trial 1 finished with value: -221.14861094379847 and parameters: {'learning_rate': 0.005639269257580862, 'n_steps': 2048, 'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.86, 'clip_range': 0.2, 'ent_coef': 0.005422933506001748, 'n_epochs': 10}. Best is trial 0 with value: -110.04965961286435.\n",
      "[I 2024-12-14 10:56:23,201] Trial 2 finished with value: -2157.822654043806 and parameters: {'learning_rate': 9.962030763316052e-05, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.955, 'gae_lambda': 0.9299999999999999, 'clip_range': 0.2, 'ent_coef': 0.0007885474648601748, 'n_epochs': 8}. Best is trial 0 with value: -110.04965961286435.\n",
      "[I 2024-12-14 10:56:37,606] Trial 3 finished with value: 15.32305078295467 and parameters: {'learning_rate': 0.009509723538524037, 'n_steps': 3584, 'batch_size': 512, 'gamma': 0.995, 'gae_lambda': 0.96, 'clip_range': 0.2, 'ent_coef': 0.00021580661991349082, 'n_epochs': 10}. Best is trial 3 with value: 15.32305078295467.\n",
      "[I 2024-12-14 10:56:57,705] Trial 4 finished with value: -1398.4382703697381 and parameters: {'learning_rate': 1.0534714940648725e-05, 'n_steps': 3072, 'batch_size': 128, 'gamma': 0.995, 'gae_lambda': 0.88, 'clip_range': 0.25, 'ent_coef': 0.00010996525611305823, 'n_epochs': 6}. Best is trial 3 with value: 15.32305078295467.\n",
      "[I 2024-12-14 10:57:29,024] Trial 5 pruned. \n",
      "[I 2024-12-14 10:57:43,806] Trial 6 pruned. \n",
      "[I 2024-12-14 10:57:58,030] Trial 7 pruned. \n",
      "[I 2024-12-14 10:58:12,079] Trial 8 pruned. \n",
      "[I 2024-12-14 10:58:27,962] Trial 9 pruned. \n",
      "[I 2024-12-14 10:58:40,516] Trial 10 pruned. \n",
      "[I 2024-12-14 10:59:14,109] Trial 11 pruned. \n",
      "[I 2024-12-14 10:59:25,914] Trial 12 pruned. \n",
      "[I 2024-12-14 10:59:39,470] Trial 13 pruned. \n",
      "[I 2024-12-14 11:00:25,105] Trial 14 finished with value: -177.48467463309336 and parameters: {'learning_rate': 0.004804175345388543, 'n_steps': 1280, 'batch_size': 32, 'gamma': 0.98, 'gae_lambda': 0.89, 'clip_range': 0.15000000000000002, 'ent_coef': 0.0003083001660213772, 'n_epochs': 9}. Best is trial 3 with value: 15.32305078295467.\n",
      "[I 2024-12-14 11:00:35,381] Trial 15 pruned. \n",
      "[I 2024-12-14 11:01:12,605] Trial 16 pruned. \n",
      "[I 2024-12-14 11:01:23,867] Trial 17 finished with value: -91.2268272836227 and parameters: {'learning_rate': 0.00021405085706274545, 'n_steps': 2560, 'batch_size': 512, 'gamma': 0.995, 'gae_lambda': 0.99, 'clip_range': 0.1, 'ent_coef': 0.013246444915620803, 'n_epochs': 7}. Best is trial 3 with value: 15.32305078295467.\n",
      "[I 2024-12-14 11:01:37,984] Trial 18 pruned. \n",
      "[I 2024-12-14 11:01:51,318] Trial 19 finished with value: -25.862042208394996 and parameters: {'learning_rate': 0.00022499252752800723, 'n_steps': 3584, 'batch_size': 512, 'gamma': 0.995, 'gae_lambda': 0.99, 'clip_range': 0.1, 'ent_coef': 0.011232872144244989, 'n_epochs': 7}. Best is trial 3 with value: 15.32305078295467.\n",
      "[I 2024-12-14 11:02:06,390] Trial 20 finished with value: -79.02933782869077 and parameters: {'learning_rate': 3.397535423003991e-05, 'n_steps': 3584, 'batch_size': 512, 'gamma': 0.985, 'gae_lambda': 0.97, 'clip_range': 0.15000000000000002, 'ent_coef': 0.0022449247323265264, 'n_epochs': 9}. Best is trial 3 with value: 15.32305078295467.\n",
      "[I 2024-12-14 11:02:27,025] Trial 21 pruned. \n",
      "[I 2024-12-14 11:02:42,589] Trial 22 pruned. \n",
      "[I 2024-12-14 11:02:56,446] Trial 23 pruned. \n",
      "[I 2024-12-14 11:03:10,373] Trial 24 finished with value: -37.708910437669694 and parameters: {'learning_rate': 0.0003222796130324683, 'n_steps': 3328, 'batch_size': 512, 'gamma': 0.985, 'gae_lambda': 0.99, 'clip_range': 0.15000000000000002, 'ent_coef': 0.000836304917414034, 'n_epochs': 10}. Best is trial 3 with value: 15.32305078295467.\n",
      "[I 2024-12-14 11:03:24,788] Trial 25 finished with value: -87.66304623587057 and parameters: {'learning_rate': 0.0010326019513638741, 'n_steps': 4096, 'batch_size': 512, 'gamma': 0.995, 'gae_lambda': 0.99, 'clip_range': 0.1, 'ent_coef': 0.0006391792237810622, 'n_epochs': 10}. Best is trial 3 with value: 15.32305078295467.\n",
      "[I 2024-12-14 11:03:54,897] Trial 26 pruned. \n",
      "[I 2024-12-14 11:04:12,619] Trial 27 pruned. \n",
      "[I 2024-12-14 11:04:27,879] Trial 28 pruned. \n",
      "[I 2024-12-14 11:04:39,706] Trial 29 pruned. \n",
      "[I 2024-12-14 11:04:53,048] Trial 30 pruned. \n",
      "[I 2024-12-14 11:05:05,536] Trial 31 pruned. \n",
      "[I 2024-12-14 11:05:20,884] Trial 32 pruned. \n",
      "[I 2024-12-14 11:05:57,269] Trial 33 pruned. \n",
      "[I 2024-12-14 11:06:08,934] Trial 34 pruned. \n",
      "[I 2024-12-14 11:06:23,428] Trial 35 pruned. \n",
      "[I 2024-12-14 11:06:46,842] Trial 36 pruned. \n",
      "[I 2024-12-14 11:07:02,349] Trial 37 pruned. \n",
      "[I 2024-12-14 11:07:29,989] Trial 38 pruned. \n",
      "[I 2024-12-14 11:07:48,092] Trial 39 pruned. \n",
      "[I 2024-12-14 11:08:04,154] Trial 40 pruned. \n",
      "[I 2024-12-14 11:08:21,101] Trial 41 finished with value: 38.350279682054975 and parameters: {'learning_rate': 0.0011382441695588768, 'n_steps': 4096, 'batch_size': 512, 'gamma': 0.995, 'gae_lambda': 0.99, 'clip_range': 0.1, 'ent_coef': 0.0007587103528023506, 'n_epochs': 10}. Best is trial 41 with value: 38.350279682054975.\n",
      "[I 2024-12-14 11:08:39,063] Trial 42 finished with value: -72.05899024152605 and parameters: {'learning_rate': 0.0012612214226566984, 'n_steps': 4096, 'batch_size': 512, 'gamma': 0.995, 'gae_lambda': 0.99, 'clip_range': 0.1, 'ent_coef': 0.0015110545089412506, 'n_epochs': 10}. Best is trial 41 with value: 38.350279682054975.\n",
      "[I 2024-12-14 11:08:54,452] Trial 43 finished with value: -5.37871239897795 and parameters: {'learning_rate': 0.001246886143073974, 'n_steps': 4096, 'batch_size': 512, 'gamma': 0.995, 'gae_lambda': 0.99, 'clip_range': 0.1, 'ent_coef': 0.0004231355960422028, 'n_epochs': 10}. Best is trial 41 with value: 38.350279682054975.\n",
      "[I 2024-12-14 11:09:10,907] Trial 44 finished with value: 67.60492756635313 and parameters: {'learning_rate': 0.0006309525881137615, 'n_steps': 3840, 'batch_size': 512, 'gamma': 0.995, 'gae_lambda': 0.98, 'clip_range': 0.1, 'ent_coef': 0.0003634808162299363, 'n_epochs': 10}. Best is trial 44 with value: 67.60492756635313.\n",
      "[I 2024-12-14 11:10:14,233] Trial 45 finished with value: 42.25035956099414 and parameters: {'learning_rate': 0.0006757685774628543, 'n_steps': 3840, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.98, 'clip_range': 0.1, 'ent_coef': 0.0004188811414950465, 'n_epochs': 10}. Best is trial 44 with value: 67.60492756635313.\n",
      "[I 2024-12-14 11:11:15,840] Trial 46 pruned. \n",
      "[I 2024-12-14 11:12:20,631] Trial 47 finished with value: -15.174023082235362 and parameters: {'learning_rate': 0.0004369199142509008, 'n_steps': 4096, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.96, 'clip_range': 0.1, 'ent_coef': 0.00013215717956349172, 'n_epochs': 10}. Best is trial 44 with value: 67.60492756635313.\n",
      "[I 2024-12-14 11:13:21,302] Trial 48 finished with value: 59.9071874926769 and parameters: {'learning_rate': 0.001976982649053419, 'n_steps': 3840, 'batch_size': 32, 'gamma': 0.99, 'gae_lambda': 0.98, 'clip_range': 0.1, 'ent_coef': 0.0002702149617489563, 'n_epochs': 9}. Best is trial 44 with value: 67.60492756635313.\n",
      "[I 2024-12-14 11:14:20,687] Trial 49 finished with value: 22.70121266703354 and parameters: {'learning_rate': 0.002043961902128968, 'n_steps': 3840, 'batch_size': 32, 'gamma': 0.99, 'gae_lambda': 0.98, 'clip_range': 0.1, 'ent_coef': 0.0002834975376375215, 'n_epochs': 9}. Best is trial 44 with value: 67.60492756635313.\n",
      "[I 2024-12-14 11:15:20,422] Trial 50 finished with value: 77.70669754339433 and parameters: {'learning_rate': 0.0018718689777793727, 'n_steps': 3840, 'batch_size': 32, 'gamma': 0.99, 'gae_lambda': 0.98, 'clip_range': 0.1, 'ent_coef': 0.00029898367298681434, 'n_epochs': 9}. Best is trial 50 with value: 77.70669754339433.\n",
      "[I 2024-12-14 11:16:16,272] Trial 51 pruned. \n",
      "[I 2024-12-14 11:17:04,032] Trial 52 finished with value: 25.264793442983706 and parameters: {'learning_rate': 0.0033157674797916624, 'n_steps': 256, 'batch_size': 32, 'gamma': 0.99, 'gae_lambda': 0.88, 'clip_range': 0.1, 'ent_coef': 0.00026250479486288427, 'n_epochs': 9}. Best is trial 50 with value: 77.70669754339433.\n",
      "[I 2024-12-14 11:18:08,660] Trial 53 pruned. \n",
      "[I 2024-12-14 11:18:55,737] Trial 54 pruned. \n",
      "[I 2024-12-14 11:19:40,836] Trial 55 finished with value: 39.844217604957976 and parameters: {'learning_rate': 0.0017253832669438696, 'n_steps': 256, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9099999999999999, 'clip_range': 0.1, 'ent_coef': 0.00024339332173253583, 'n_epochs': 9}. Best is trial 50 with value: 77.70669754339433.\n",
      "[I 2024-12-14 11:20:34,202] Trial 56 pruned. \n",
      "[I 2024-12-14 11:21:24,456] Trial 57 pruned. \n",
      "[I 2024-12-14 11:22:19,136] Trial 58 pruned. \n",
      "[I 2024-12-14 11:23:03,951] Trial 59 pruned. \n",
      "[I 2024-12-14 11:23:48,269] Trial 60 pruned. \n",
      "[I 2024-12-14 11:24:33,062] Trial 61 pruned. \n",
      "[I 2024-12-14 11:25:23,153] Trial 62 finished with value: 26.858890878690325 and parameters: {'learning_rate': 0.0007396405213900199, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.00033884059598526014, 'n_epochs': 10}. Best is trial 50 with value: 77.70669754339433.\n",
      "[I 2024-12-14 11:26:13,792] Trial 63 pruned. \n",
      "[I 2024-12-14 11:27:07,336] Trial 64 finished with value: 114.47674186922418 and parameters: {'learning_rate': 0.0011000003536546332, 'n_steps': 768, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9199999999999999, 'clip_range': 0.1, 'ent_coef': 0.0004133463183556083, 'n_epochs': 10}. Best is trial 64 with value: 114.47674186922418.\n",
      "[I 2024-12-14 11:28:01,565] Trial 65 pruned. \n",
      "[I 2024-12-14 11:28:52,370] Trial 66 pruned. \n",
      "[I 2024-12-14 11:29:08,754] Trial 67 pruned. \n",
      "[I 2024-12-14 11:30:08,736] Trial 68 pruned. \n",
      "[I 2024-12-14 11:30:37,671] Trial 69 pruned. \n",
      "[I 2024-12-14 11:31:11,994] Trial 70 pruned. \n",
      "[I 2024-12-14 11:32:02,933] Trial 71 finished with value: 75.59144199352758 and parameters: {'learning_rate': 0.000717327737641685, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.89, 'clip_range': 0.1, 'ent_coef': 0.0003508925334173157, 'n_epochs': 10}. Best is trial 64 with value: 114.47674186922418.\n",
      "[I 2024-12-14 11:32:51,672] Trial 72 finished with value: 105.32099305931197 and parameters: {'learning_rate': 0.0009125130221572325, 'n_steps': 256, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.94, 'clip_range': 0.1, 'ent_coef': 0.0004019644542275206, 'n_epochs': 10}. Best is trial 64 with value: 114.47674186922418.\n",
      "[I 2024-12-14 11:33:37,959] Trial 73 pruned. \n",
      "[I 2024-12-14 11:34:29,532] Trial 74 pruned. \n",
      "[I 2024-12-14 11:35:23,004] Trial 75 pruned. \n",
      "[I 2024-12-14 11:36:13,249] Trial 76 pruned. \n",
      "[I 2024-12-14 11:36:34,067] Trial 77 finished with value: 94.68720628492119 and parameters: {'learning_rate': 0.0019311186269072003, 'n_steps': 768, 'batch_size': 128, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.00032936423622333436, 'n_epochs': 9}. Best is trial 64 with value: 114.47674186922418.\n",
      "[I 2024-12-14 11:36:55,211] Trial 78 pruned. \n",
      "[I 2024-12-14 11:37:11,200] Trial 79 pruned. \n",
      "[I 2024-12-14 11:37:31,207] Trial 80 pruned. \n",
      "[I 2024-12-14 11:37:52,596] Trial 81 finished with value: 75.56970528267848 and parameters: {'learning_rate': 0.0021357325980922437, 'n_steps': 512, 'batch_size': 128, 'gamma': 0.995, 'gae_lambda': 0.9099999999999999, 'clip_range': 0.1, 'ent_coef': 0.00024615016930768467, 'n_epochs': 9}. Best is trial 64 with value: 114.47674186922418.\n",
      "[I 2024-12-14 11:38:14,452] Trial 82 pruned. \n",
      "[I 2024-12-14 11:38:38,501] Trial 83 pruned. \n",
      "[I 2024-12-14 11:39:00,905] Trial 84 pruned. \n",
      "[I 2024-12-14 11:39:24,224] Trial 85 pruned. \n",
      "[I 2024-12-14 11:39:45,271] Trial 86 pruned. \n",
      "[I 2024-12-14 11:40:03,508] Trial 87 pruned. \n",
      "[I 2024-12-14 11:40:38,990] Trial 88 pruned. \n",
      "[I 2024-12-14 11:41:54,537] Trial 89 pruned. \n",
      "[I 2024-12-14 11:42:18,873] Trial 90 pruned. \n",
      "[I 2024-12-14 11:43:02,022] Trial 91 finished with value: 127.30730934955375 and parameters: {'learning_rate': 0.0017669296415867937, 'n_steps': 256, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9099999999999999, 'clip_range': 0.1, 'ent_coef': 0.0003780691880102494, 'n_epochs': 9}. Best is trial 91 with value: 127.30730934955375.\n",
      "[I 2024-12-14 11:43:50,238] Trial 92 pruned. \n",
      "[I 2024-12-14 11:44:34,707] Trial 93 pruned. \n",
      "[I 2024-12-14 11:45:24,289] Trial 94 finished with value: 85.32039356519833 and parameters: {'learning_rate': 0.0015682213317815166, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.000246591304563462, 'n_epochs': 10}. Best is trial 91 with value: 127.30730934955375.\n",
      "[I 2024-12-14 11:46:17,556] Trial 95 pruned. \n",
      "[I 2024-12-14 11:47:03,831] Trial 96 finished with value: 186.2546596718161 and parameters: {'learning_rate': 0.003010104729314347, 'n_steps': 768, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.89, 'clip_range': 0.1, 'ent_coef': 0.00023171717438955102, 'n_epochs': 8}. Best is trial 96 with value: 186.2546596718161.\n",
      "[I 2024-12-14 11:47:49,142] Trial 97 pruned. \n",
      "[I 2024-12-14 11:48:30,291] Trial 98 finished with value: 204.56898206018877 and parameters: {'learning_rate': 0.006423769910846423, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.00022537246173760854, 'n_epochs': 7}. Best is trial 98 with value: 204.56898206018877.\n",
      "[I 2024-12-14 11:49:14,338] Trial 99 finished with value: 44.80228363787173 and parameters: {'learning_rate': 0.007966375806943163, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.00020852751088725884, 'n_epochs': 7}. Best is trial 98 with value: 204.56898206018877.\n",
      "[I 2024-12-14 11:50:01,588] Trial 100 pruned. \n",
      "[I 2024-12-14 11:50:40,797] Trial 101 pruned. \n",
      "[I 2024-12-14 11:51:23,644] Trial 102 pruned. \n",
      "[I 2024-12-14 11:52:08,899] Trial 103 pruned. \n",
      "[I 2024-12-14 11:52:22,883] Trial 104 pruned. \n",
      "[I 2024-12-14 11:52:47,887] Trial 105 pruned. \n",
      "[I 2024-12-14 11:53:43,149] Trial 106 pruned. \n",
      "[I 2024-12-14 11:54:20,968] Trial 107 pruned. \n",
      "[I 2024-12-14 11:55:10,963] Trial 108 pruned. \n",
      "[I 2024-12-14 11:55:58,426] Trial 109 pruned. \n",
      "[I 2024-12-14 11:56:44,228] Trial 110 pruned. \n",
      "[I 2024-12-14 11:57:34,753] Trial 111 pruned. \n",
      "[I 2024-12-14 11:58:23,094] Trial 112 pruned. \n",
      "[I 2024-12-14 11:59:11,955] Trial 113 pruned. \n",
      "[I 2024-12-14 11:59:57,706] Trial 114 finished with value: 238.51914107394677 and parameters: {'learning_rate': 0.002164447901112235, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.89, 'clip_range': 0.1, 'ent_coef': 0.0001652124469384415, 'n_epochs': 9}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:00:47,333] Trial 115 pruned. \n",
      "[I 2024-12-14 12:01:08,852] Trial 116 pruned. \n",
      "[I 2024-12-14 12:01:46,754] Trial 117 pruned. \n",
      "[I 2024-12-14 12:01:59,608] Trial 118 pruned. \n",
      "[I 2024-12-14 12:02:47,268] Trial 119 pruned. \n",
      "[I 2024-12-14 12:03:44,432] Trial 120 pruned. \n",
      "[I 2024-12-14 12:04:33,079] Trial 121 finished with value: 122.01754338319734 and parameters: {'learning_rate': 0.0019885438704649438, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.00032915228393594445, 'n_epochs': 9}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:05:25,169] Trial 122 pruned. \n",
      "[I 2024-12-14 12:06:10,001] Trial 123 pruned. \n",
      "[I 2024-12-14 12:06:54,597] Trial 124 finished with value: 116.35657984457282 and parameters: {'learning_rate': 0.004209190601309185, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.89, 'clip_range': 0.1, 'ent_coef': 0.00017911546127187002, 'n_epochs': 8}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:07:40,474] Trial 125 pruned. \n",
      "[I 2024-12-14 12:08:23,211] Trial 126 pruned. \n",
      "[I 2024-12-14 12:09:04,386] Trial 127 pruned. \n",
      "[I 2024-12-14 12:09:39,374] Trial 128 pruned. \n",
      "[I 2024-12-14 12:10:29,556] Trial 129 pruned. \n",
      "[I 2024-12-14 12:10:50,298] Trial 130 pruned. \n",
      "[I 2024-12-14 12:11:53,700] Trial 131 finished with value: 43.3881918955929 and parameters: {'learning_rate': 0.004035615732043293, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.89, 'clip_range': 0.1, 'ent_coef': 0.00041038539653810496, 'n_epochs': 10}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:12:43,727] Trial 132 pruned. \n",
      "[I 2024-12-14 12:12:55,479] Trial 133 pruned. \n",
      "[I 2024-12-14 12:13:57,471] Trial 134 pruned. \n",
      "[I 2024-12-14 12:14:14,093] Trial 135 pruned. \n",
      "[I 2024-12-14 12:14:41,196] Trial 136 pruned. \n",
      "[I 2024-12-14 12:15:01,652] Trial 137 pruned. \n",
      "[I 2024-12-14 12:15:50,969] Trial 138 pruned. \n",
      "[I 2024-12-14 12:16:13,522] Trial 139 pruned. \n",
      "[I 2024-12-14 12:17:07,634] Trial 140 pruned. \n",
      "[I 2024-12-14 12:18:01,262] Trial 141 pruned. \n",
      "[I 2024-12-14 12:18:48,399] Trial 142 pruned. \n",
      "[I 2024-12-14 12:19:39,261] Trial 143 pruned. \n",
      "[I 2024-12-14 12:20:37,867] Trial 144 pruned. \n",
      "[I 2024-12-14 12:21:23,816] Trial 145 pruned. \n",
      "[I 2024-12-14 12:21:43,911] Trial 146 pruned. \n",
      "[I 2024-12-14 12:21:57,952] Trial 147 pruned. \n",
      "[I 2024-12-14 12:22:48,480] Trial 148 pruned. \n",
      "[I 2024-12-14 12:23:18,495] Trial 149 pruned. \n",
      "[I 2024-12-14 12:24:05,412] Trial 150 pruned. \n",
      "[I 2024-12-14 12:24:43,067] Trial 151 pruned. \n",
      "[I 2024-12-14 12:25:24,779] Trial 152 pruned. \n",
      "[I 2024-12-14 12:25:58,905] Trial 153 pruned. \n",
      "[I 2024-12-14 12:26:37,498] Trial 154 finished with value: 134.87068340776628 and parameters: {'learning_rate': 0.005294274095081359, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.00010007271016894396, 'n_epochs': 7}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:27:19,436] Trial 155 pruned. \n",
      "[I 2024-12-14 12:27:44,319] Trial 156 pruned. \n",
      "[I 2024-12-14 12:28:37,107] Trial 157 pruned. \n",
      "[I 2024-12-14 12:28:51,971] Trial 158 pruned. \n",
      "[I 2024-12-14 12:29:37,951] Trial 159 pruned. \n",
      "[I 2024-12-14 12:30:12,232] Trial 160 pruned. \n",
      "[I 2024-12-14 12:30:54,706] Trial 161 finished with value: 83.7517140794138 and parameters: {'learning_rate': 0.006761216769270134, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.00019342533284364278, 'n_epochs': 7}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:31:31,940] Trial 162 finished with value: 50.64330022299323 and parameters: {'learning_rate': 0.006777738642029828, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.0001775634142539497, 'n_epochs': 7}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:32:13,254] Trial 163 pruned. \n",
      "[I 2024-12-14 12:32:54,516] Trial 164 pruned. \n",
      "[I 2024-12-14 12:33:33,261] Trial 165 pruned. \n",
      "[I 2024-12-14 12:33:45,241] Trial 166 pruned. \n",
      "[I 2024-12-14 12:34:35,113] Trial 167 pruned. \n",
      "[I 2024-12-14 12:35:25,508] Trial 168 pruned. \n",
      "[I 2024-12-14 12:35:44,427] Trial 169 pruned. \n",
      "[I 2024-12-14 12:36:22,241] Trial 170 pruned. \n",
      "[I 2024-12-14 12:37:03,381] Trial 171 pruned. \n",
      "[I 2024-12-14 12:37:42,162] Trial 172 finished with value: 98.71902938154963 and parameters: {'learning_rate': 0.006230598527984026, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.0001615410051062999, 'n_epochs': 7}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:38:24,003] Trial 173 pruned. \n",
      "[I 2024-12-14 12:39:04,415] Trial 174 finished with value: 84.09985055974985 and parameters: {'learning_rate': 0.003900643207811643, 'n_steps': 768, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9099999999999999, 'clip_range': 0.1, 'ent_coef': 0.00022527666095181574, 'n_epochs': 7}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:39:51,852] Trial 175 pruned. \n",
      "[I 2024-12-14 12:40:30,920] Trial 176 pruned. \n",
      "[I 2024-12-14 12:41:11,174] Trial 177 pruned. \n",
      "[I 2024-12-14 12:41:51,790] Trial 178 pruned. \n",
      "[I 2024-12-14 12:42:28,342] Trial 179 pruned. \n",
      "[I 2024-12-14 12:42:40,694] Trial 180 pruned. \n",
      "[I 2024-12-14 12:43:33,279] Trial 181 pruned. \n",
      "[I 2024-12-14 12:44:24,853] Trial 182 pruned. \n",
      "[I 2024-12-14 12:45:16,781] Trial 183 pruned. \n",
      "[I 2024-12-14 12:46:10,092] Trial 184 finished with value: 81.51132882888487 and parameters: {'learning_rate': 0.0022414563851933657, 'n_steps': 768, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.0002533696711623853, 'n_epochs': 10}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:47:02,284] Trial 185 pruned. \n",
      "[I 2024-12-14 12:47:24,506] Trial 186 pruned. \n",
      "[I 2024-12-14 12:48:21,282] Trial 187 pruned. \n",
      "[I 2024-12-14 12:49:14,772] Trial 188 pruned. \n",
      "[I 2024-12-14 12:50:11,304] Trial 189 finished with value: 78.96799413420668 and parameters: {'learning_rate': 0.00249664013735777, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.89, 'clip_range': 0.1, 'ent_coef': 0.00029608257966798817, 'n_epochs': 10}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:51:06,439] Trial 190 pruned. \n",
      "[I 2024-12-14 12:52:00,057] Trial 191 pruned. \n",
      "[I 2024-12-14 12:52:53,772] Trial 192 finished with value: 63.00532563609272 and parameters: {'learning_rate': 0.002131871798723294, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.0002928694388309591, 'n_epochs': 10}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:53:46,238] Trial 193 pruned. \n",
      "[I 2024-12-14 12:54:40,224] Trial 194 pruned. \n",
      "[I 2024-12-14 12:55:23,993] Trial 195 pruned. \n",
      "[I 2024-12-14 12:56:19,873] Trial 196 finished with value: 72.0994750454629 and parameters: {'learning_rate': 0.0018257544172739484, 'n_steps': 768, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.0002536344553082031, 'n_epochs': 10}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:57:16,739] Trial 197 finished with value: 115.30623782903226 and parameters: {'learning_rate': 0.0020910429686900704, 'n_steps': 768, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9, 'clip_range': 0.1, 'ent_coef': 0.017301568335948512, 'n_epochs': 10}. Best is trial 114 with value: 238.51914107394677.\n",
      "[I 2024-12-14 12:57:58,565] Trial 198 pruned. \n",
      "[I 2024-12-14 12:58:48,172] Trial 199 finished with value: 119.07925378276323 and parameters: {'learning_rate': 0.0030276500762918108, 'n_steps': 768, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.9099999999999999, 'clip_range': 0.1, 'ent_coef': 0.00019884703313578542, 'n_epochs': 10}. Best is trial 114 with value: 238.51914107394677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.002164447901112235, 'n_steps': 512, 'batch_size': 32, 'gamma': 0.995, 'gae_lambda': 0.89, 'clip_range': 0.1, 'ent_coef': 0.0001652124469384415, 'n_epochs': 9}\n",
      "Best accuracy: 238.51914107394677\n"
     ]
    }
   ],
   "source": [
    "# Run the optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: gym.make(\"LunarLander-v3\") for _ in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.002164447901112235,\n",
       " 'n_steps': 512,\n",
       " 'batch_size': 32,\n",
       " 'gamma': 0.995,\n",
       " 'gae_lambda': 0.89,\n",
       " 'clip_range': 0.1,\n",
       " 'ent_coef': 0.0001652124469384415,\n",
       " 'n_epochs': 9}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the LunarLander-v3 environment\n",
    "\n",
    "# Initialize the PPO agent with the environment\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",  # Multi-layer perceptron policy\n",
    "    env=env,             # Environment\n",
    "    verbose=0,           # Logging level\n",
    "    learning_rate=best_params['learning_rate'],  # Learning rate\n",
    "    gamma=best_params['gamma'],          # Discount factor\n",
    "    n_steps=best_params['n_steps'],        # Number of steps to run for each environment per update\n",
    "    batch_size=best_params['batch_size'],       # Mini-batch size\n",
    "    gae_lambda=best_params['gae_lambda'],         # lambda\n",
    "    ent_coef=best_params['ent_coef'],\n",
    "    clip_range= best_params['clip_range'],\n",
    "    n_epochs= best_params[\"n_epochs\"],\n",
    ")\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=1000000)  # Train for 1,000,000 steps\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_lunarlander_best\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"ppo_lunarlander_best\", env = env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaomeiwang/Desktop/DeepRL/my_lunar_env/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward = 267.9496877070079, Std Reward = 21.550040399440356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env.reset()\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Mean Reward = {mean_reward}, Std Reward = {std_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "video_folder = \"videostest\"  # Directory to save the video\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "env = RecordVideo(env, video_folder=video_folder, episode_trigger=lambda x: True)\n",
    "\n",
    "model = PPO.load(\"ppo_lunarlander_best\", env=env)\n",
    "\n",
    "# Test the trained agent\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_lunar_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
